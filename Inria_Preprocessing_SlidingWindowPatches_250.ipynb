{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inria_Preprocessing_SlidingWindowPatches_250.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pallavi-allada/experiments-with-data/blob/master/Inria_Preprocessing_SlidingWindowPatches_250.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oKeh2HQXcPY",
        "colab_type": "text"
      },
      "source": [
        "## **Inria Aerial Satellite Image Labelling**\n",
        "The main aim of this challenge is to be able to classify pixels as 'building' or 'not building'. This is a clear case of semantic segmentation. We have180 aerial images from various cities with a resolution of 5000 X 5000, along with the segmented masks of 5000 X 5000. Our goal is to classify each of the pixels in the test image and generate a masks for the test images too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqCQtcktF0kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash\n",
        "!pip install PyDrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x10JWzM1BGR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4weziruaEBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile,re,os,pathlib,shutil\n",
        "\n",
        "import fastai\n",
        "from fastai.vision import *\n",
        "import torch\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMqPP8KxX_Zc",
        "colab_type": "text"
      },
      "source": [
        "## Download Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAhBTN6qyBBo",
        "colab_type": "text"
      },
      "source": [
        "Downloading the dataset images from the URL mentioned in the inria site using curl cmd. This command downloads the dataset as 7z parts and then unzips it under the folder AerialImageDataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3GI6p0MXqV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do not execute !! Already downloaded datasets !\n",
        "!curl -k https://files.inria.fr/aerialimagelabeling/getAerial.sh | bash"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dv7ayja6qjX",
        "colab_type": "text"
      },
      "source": [
        "Remove dependent 7z parts and zip file once unzipping is completed to clear some storage space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXG_e3ugsZAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf /content/aerialimagelabeling*\n",
        "!rm -rf /content/NEW2-AerialImageDataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r802b5aZCIV2",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess the data \n",
        "Since each image is of a high dimension and we only have 180 training images, we can take 2 approaches - \n",
        "1) Resize the image to lower dimensions like 250 X 250 and then train the network on the resized images.\n",
        "2) Slice each image of 5k X 5k over a sliding window stride of 250 to generate an image of size 250 X 250 and train the network on the patches. This approach generates ~400 image patches for each 5k X 5k image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMIRg8NTCG1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_path = Path('/content/AerialImageDataset/train/images')\n",
        "mask_path = Path('/content/AerialImageDataset/train/gt')\n",
        "test_path = Path('/content/AerialImageDataset/test/images')\n",
        "valid_path = Path('/content/AerialImageDataset/valid')\n",
        "\n",
        "images_patch_path = Path('/content/AerialImagePatches/train')\n",
        "masks_patch_path = Path('/content/AerialImagePatches/masks')\n",
        "tests_patch_path = Path('/content/AerialImagePatches/test')\n",
        "valids_patch_path = Path('/content/AerialImagePatches/valid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUe_KfYrfr2O",
        "colab_type": "text"
      },
      "source": [
        "Split train to valid by moving the first 5 images from each city to valid folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SRR9XrzfqM4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#move first five images from each city for valid hold outs\n",
        "\n",
        "def train_valid_split(src: str, dst: str):\n",
        "  if not os.path.isdir(dst):\n",
        "    dst.mkdir(parents=True, exist_ok=True)\n",
        "  for file in os.listdir(src):\n",
        "    if re.match(\"[a-zA-Z]*[1-5]{1}\\.tif\", file) or re.match(\"[a-zA-Z]*-\\w[1-5]{1}\\.tif\", file):\n",
        "      shutil.move(src/file, dst/file)\n",
        "        \n",
        "train_valid_split(img_path,valid_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBCUlr0uQ0_H",
        "colab_type": "text"
      },
      "source": [
        "Clean up any previously created folder for AerialImagePatches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiYVAHaMQ94Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf AerialImagePatches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8HzXjLFDkvG",
        "colab_type": "text"
      },
      "source": [
        "Functions to generate patches of 250 X 250 from 5k X 5k images and save it for training model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Svtt1GHNiEw",
        "colab_type": "code",
        "outputId": "8aaf048e-c754-4997-e4b1-840e5f919895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "orig_images = ImageList.from_folder(img_path)\n",
        "orig_valids = ImageList.from_folder(valid_path)\n",
        "orig_masks = ImageList.from_folder(mask_path)\n",
        "orig_tests = ImageList.from_folder(test_path)\n",
        "\n",
        "get_patch_file_name = lambda pth,x,y: pth/f'{x.stem.split(\"/\")[-1]}_{y}.tif'\n",
        "\n",
        "channels = 3\n",
        "size = 250\n",
        "step = 250\n",
        "\n",
        "\n",
        "def generate_patches(image, i, dest_img_path, channels:int, size:int, step:int):\n",
        "  img = open_image(image)\n",
        "  patches = img.data.unfold(0, channels, channels).unfold(1, size, step).unfold(2, size, step)\n",
        "  cnt=1\n",
        "  for i in range(patches.shape[0]):\n",
        "    for j in range(patches.shape[1]):\n",
        "      for k in range(patches.shape[2]):\n",
        "        patch = patches[i][j][k]\n",
        "        imgpil = F.to_pil_image(patch)\n",
        "        filname = get_patch_file_name(dest_img_path, image, cnt)\n",
        "        cnt=cnt+1\n",
        "        imgpil.save(filname)\n",
        "\n",
        "# create smaller patch sets \n",
        "sets = [(orig_images,images_patch_path,channels,size,step),(orig_valids,valids_patch_path,channels,size,step),(orig_masks, masks_patch_path,channels,size,step),(orig_tests,tests_patch_path,channels,size,step)]\n",
        "for img_lst,dst_path,channels,size,step in sets:\n",
        "  if not dst_path.exists():\n",
        "    dst_path.mkdir(parents=True, exist_ok=True)\n",
        "  parallel(partial(generate_patches, dest_img_path=dst_path, channels=channels, size=size, step=step), img_lst.items)\n",
        "\n",
        "        "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='155' class='' max='155', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [155/155 03:44<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='25' class='' max='25', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [25/25 00:40<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='180' class='' max='180', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [180/180 03:29<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='180' class='' max='180', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [180/180 04:27<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4vtpgi3EIsu",
        "colab_type": "text"
      },
      "source": [
        "Now, the training set of 180 images of 5k x 5k is converted into a training set of 60450 patches of 250 x 250 each, along with corresponding 60450 patches for the masks as well. Valid set contains 9750 patches of 250 x 250."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqJXDynVb3om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(get_image_files(img_path)),len(get_image_files(mask_path)),len(get_image_files(valid_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxuBnW9AbDgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(get_image_files(images_patch_path)),len(get_image_files(masks_patch_path)), len(get_image_files(valids_patch_path))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJfXmmLijpq0",
        "colab_type": "text"
      },
      "source": [
        "Function to create tar file for moving to Drive for future use. This helps in avoiding redundant preprocessing each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQA2w_khnWiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_source_dir = '/content/AerialImagePatches/train'\n",
        "valid_source_dir = '/content/AerialImagePatches/valid'\n",
        "mask_source_dir = '/content/AerialImagePatches/masks'\n",
        "test_source_dir = '/content/AerialImagePatches/test'\n",
        "\n",
        "def make_tarfile(output_filename, source_dir):\n",
        "  with tarfile.open(output_filename, \"w:gz\") as tar:\n",
        "    tar.add(source_dir, arcname=os.path.basename(source_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0j8JTMfG3sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_tarfile('train.tar', train_source_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io1NoYQ7xHNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_tarfile('masks.tar', mask_source_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6ej7bU8ntH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "make_tarfile('valid.tar', valid_source_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c78IQr-knMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tar test folder only when needed as Drive only has 15GB by default\n",
        "make_tarfile('test.tar', test_source_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B82GCKalFho",
        "colab_type": "text"
      },
      "source": [
        "Function to upload to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2PEoLX6bDIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create GoogleDrive instance with authenticated GoogleAuth instance.\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "def upload_to_drive(file, title):\n",
        "  uploaded = drive.CreateFile({'title': title})\n",
        "  uploaded.SetContentFile(file)\n",
        "  uploaded.Upload()\n",
        "  print('Uploaded file %s with ID %s'%(file, uploaded.get('id')))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld8Wr3o3llFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload_to_drive(\"train.tar\",\"train.tar\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i85HBtFDlzay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload_to_drive(\"masks.tar\",\"masks.tar\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbkeYl04efPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload_to_drive(\"valid.tar\",\"valid.tar\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tECv-wTJml8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "upload_to_drive(\"test.tar\",\"test.tar\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GFNkc41lvgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}